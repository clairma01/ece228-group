{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import averageMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labeled images: 2738\n"
     ]
    }
   ],
   "source": [
    "# setup transform\n",
    "# train_transforms = transforms.ToTensor()\n",
    "# val_transforms = transforms.ToTensor()\n",
    "\n",
    "# TODO: INCOMPLETE, have not loaded labels\n",
    "h_size = 2384\n",
    "w_size = 4240\n",
    "\n",
    "# load dataset\n",
    "drive_path = \"D:\\\\Edited\\\\1\\\\\"\n",
    "box_paths = \"D:\\\\Edited\\\\1\\\\*\\\\*.csv\"\n",
    "day_folders = []\n",
    "for i in range(10,24):\n",
    "    day_folders.append(drive_path + \"1807\" + str(i) + \" - Edited\")\n",
    "\n",
    "box_paths = glob.glob(box_paths)\n",
    "set_len = len(box_paths)\n",
    "print(\"Number of labeled images: \" + str(set_len))\n",
    "subset_len = set_len // 5\n",
    "# train_len = set_len - test_len\n",
    "\n",
    "random.shuffle(box_paths)\n",
    "test_names = box_paths[:subset_len]\n",
    "train_names1 = box_paths[subset_len:subset_len*2]\n",
    "train_names2 = box_paths[subset_len*2:subset_len*3]\n",
    "train_names3 = box_paths[subset_len*3:subset_len*4]\n",
    "train_names4 = box_paths[subset_len*4:]\n",
    "\n",
    "train_dataset = np.array([np.array(Image.open(fname[:-4] + \".jpg\")) for fname in train_names1])\n",
    "test_dataset = np.array([np.array(Image.open(fname[:-4] + \".jpg\")) for fname in test_names])\n",
    "\n",
    "# # unit-test\n",
    "# train_loader = DataLoader(train_dataset, batch_size=4)\n",
    "# value = next(iter(train_loader))\n",
    "# data = value[0]\n",
    "# target = value[1]\n",
    "# print(data.shape)\n",
    "# print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: INCOMPLETE, change to Euclidean norm-based accuracy? since no longer a discrete class prediction\n",
    "def compute_accuracy(output, target):\n",
    "    ########### TODO ###########\n",
    "    # compute the accuracy of the prediction\n",
    "    predict = torch.argmax(output, 1)\n",
    "    total = target.size()[0]\n",
    "    same = torch.sum(predict == target)\n",
    "    acc = same/total\n",
    "    ######## End of TODO #######\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, optimizer, epoch, criterion, device='cpu'):\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    losses = averageMeter()\n",
    "    accuracy = averageMeter()\n",
    "    for (step, value) in enumerate(data_loader):\n",
    "\n",
    "        data = value[0].to(device)\n",
    "        target = value[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward the data to the model and get the output\n",
    "        output = model(data)\n",
    "\n",
    "        # compute accuracy\n",
    "        acc = compute_accuracy(output, target)\n",
    "        accuracy.update(acc.item(), data.size(0))\n",
    "\n",
    "        # compute loss with the output and the target\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # backward (PyTorch computes backpropagation for you)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # accumulate losses\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "\n",
    "    print(f\"[Epoch: {epoch}]\\t lr: {optimizer.param_groups[0]['lr']:.4g}\\t \\\n",
    "      loss_train: {losses.avg:.4f}\\tacc_train: {accuracy.avg:.4f}\")\n",
    "    return losses.avg, accuracy.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(data_loader, model, criterion, device='cpu'):\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    losses = averageMeter()\n",
    "    accuracy = averageMeter()\n",
    "    for (step, value) in enumerate(data_loader):\n",
    "\n",
    "        data = value[0].to(device)\n",
    "        target = value[1].to(device)\n",
    "\n",
    "        # forward the data to the model and get the output\n",
    "        output = model(data)\n",
    "\n",
    "        # compute accuracy\n",
    "        acc = compute_accuracy(output, target)\n",
    "        accuracy.update(acc.item(), data.size(0))\n",
    "\n",
    "        # compute loss with the output and the target\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # accumulate losses\n",
    "        losses.update(loss.item(), data.size(0))\n",
    "\n",
    "    return losses.avg, accuracy.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: untested, should be updated to increase accuracy as necessary\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        ########### TODO ###########\n",
    "        self.conv1 = nn.Conv2d(1,4,3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avgpool = nn.AvgPool2d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(4,16,3)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16,32,3)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(32,32,3)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(32,32,3)\n",
    "\n",
    "        self.out = nn.Linear(1237152, 4)\n",
    "\n",
    "        ######## End of TODO #######\n",
    "\n",
    "    def forward(self, x):\n",
    "        ########### TODO ###########\n",
    "        # forward the input x to the model to get the output\n",
    "        # 2384 x 4240\n",
    "        conv1x = self.conv1(x)\n",
    "        # 2382 x 4238 x 4\n",
    "        conv1x = self.relu(conv1x)\n",
    "        # print(conv1x.shape)\n",
    "\n",
    "        # 2382 x 4238 x 4\n",
    "        conv2x = self.conv2(conv1x)\n",
    "        # 2380 x 4236 x 16\n",
    "        conv2x = self.relu(conv2x)\n",
    "        conv2x = self.avgpool(conv2x)\n",
    "        # print(conv2x.shape)\n",
    "\n",
    "        # 1190 x 2118 x 16\n",
    "        conv3x = self.conv3(conv2x)\n",
    "        # 1188 x 2116 x 32\n",
    "        conv3x = self.relu(conv3x)\n",
    "        # print(conv3x.shape)\n",
    "        conv3x = self.avgpool(conv3x)\n",
    "\n",
    "        # 594 x 1058 x 32\n",
    "        conv4x = self.conv4(conv3x)\n",
    "        # 592 x 1056 x 32\n",
    "        conv4x = self.relu(conv4x)\n",
    "        conv4x = self.avgpool(conv4x)\n",
    "\n",
    "        # 296 x 528 x 32\n",
    "        conv4x = self.conv4(conv3x)\n",
    "        # 294 x 526 x 32\n",
    "        conv4x = self.relu(conv4x)\n",
    "        conv4x = self.avgpool(conv4x)\n",
    "\n",
    "        # 147 x 263 x 32\n",
    "        flat = torch.flatten(conv3x,1,3)\n",
    "        # 1237152\n",
    "        x = self.out(flat)\n",
    "        ######## End of TODO #######\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CNN(batch_size=64, lr=0.1, n_epoch=30, eval_epoch=5):\n",
    "\n",
    "    # setup random seed\n",
    "    torch.manual_seed(1337)\n",
    "    torch.cuda.manual_seed(1337)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # setup model\n",
    "    model = CNN()\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        device = 'cuda'\n",
    "\n",
    "    # setup data loader\n",
    "    train_loader = DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    drop_last=True\n",
    "                )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "                    test_dataset,\n",
    "                    batch_size=128,\n",
    "                    shuffle=False,\n",
    "                    drop_last=False\n",
    "                )\n",
    "\n",
    "    # setup optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    ########### TODO ###########\n",
    "    # setup loss function (criterion)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    ######## End of TODO #######\n",
    "\n",
    "    # training and evaluation\n",
    "    losses_train = []\n",
    "    accs_train = []\n",
    "    losses_test = []\n",
    "    accs_test = []\n",
    "    for ep in range(n_epoch):\n",
    "\n",
    "        # train an epoch and get the loss\n",
    "        loss_train, acc_train = train(train_loader, model, optimizer, ep, criterion, device)\n",
    "        losses_train.append(loss_train)\n",
    "        accs_train.append(acc_train)\n",
    "\n",
    "        if (ep + 1) % eval_epoch == 0:\n",
    "            # evaluate current model and get the loss\n",
    "            loss_test, acc_test = test(test_loader, model, criterion, device)\n",
    "            losses_test.append(loss_test)\n",
    "            accs_test.append(acc_test)\n",
    "            print(f'[val]\\tloss_test: {loss_test:.4f}\\tacc_test: {acc_test:.4f}')\n",
    "\n",
    "    # plot the training/testing loss and accuracy\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 3))\n",
    "    ax[0].plot(np.arange(n_epoch), losses_train, color='b', label='train_loss')\n",
    "    ax[0].plot(np.linspace(0, n_epoch, n_epoch//eval_epoch), losses_test, color='r', label='test_loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(np.arange(n_epoch), accs_train, color='b', label='train_acc')\n",
    "    ax[1].plot(np.linspace(0, n_epoch, n_epoch//eval_epoch), accs_test, color='r', label='test_acc')\n",
    "    ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CNN()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
